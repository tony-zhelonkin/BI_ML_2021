{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88fe2596-8e7c-4c97-b347-7468994508f8",
   "metadata": {},
   "source": [
    "# Домашнее задание №2 - Линейные модели. Градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44123a57-0d05-4714-8fec-f4f4c6d254e0",
   "metadata": {},
   "source": [
    "В этом домашнем задании мы с вами научимся обучать линейные модели регрессии и классификации при помощи очень мощного, но в то же время довольно понятного алгоритма, который называется **градиетный спуск**. Помимо линейных моделей он используется и для обучения самых сложных нейронных сетей! Также мы потренируемся применять готовые реализации линейных моделей для задач регрессии и бинарной классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a204ec7b-1f3c-439c-8a9e-0abbe270e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.linear_model import (LinearRegression,\n",
    "                                  LogisticRegression)\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import (r2_score,\n",
    "                             mean_squared_error)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "340f9411-bcff-4fae-a4a7-3c42361de2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = 12, 9\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "SEED = 111\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585743eb-64a7-473e-832d-4e11ffb6ba87",
   "metadata": {},
   "source": [
    "#### Маленькое теоретическое отступление\n",
    "\n",
    "Основное свойство антиградиента (-1 * градиент) &ndash; он указывает в сторону наискорейшего убывания функции в данной точке. Соответственно, будет логично стартовать из некоторой точки, сдвинуться в сторону антиградиента, пересчитать антиградиент и снова сдвинуться в его сторону и т.д. Запишем это более формально.\n",
    "\n",
    "Пусть $w_0$ &ndash; начальный набор параметров (коэффициентов линейной модели) ((например, нулевой или сгенерированный из некоторого, случайного распределения)). Тогда обычный градиентный спуск состоит в повторении следующих шагов до сходимости:\n",
    "\n",
    "\n",
    "$$\n",
    "    w_{k + 1} = w_{k} - \\eta \\nabla_{w} Q(w_{k}),\n",
    "$$\n",
    "\n",
    "где $\\nabla_{w} Q(w_{k})$ &ndash; градиент функции потерь в точке $w_k$, а $\\eta$ &ndash; скорость обучения (learning rate).\n",
    "\n",
    "Градиентный спуск обычно останавливают, когда прошло заданное максимальное количество итераций или когда графиент близок к нулю (т.е. наши параметры практически не меняются). Для реализации второго варианта считают норму градиента (по сути длину вектора). Это можно сделать несколькими способами:\n",
    "\n",
    "$$\n",
    "l1_{norm} = \\sum{|w_i|}\n",
    "$$\n",
    "\n",
    "$$\n",
    "l2_{norm} = \\sum{(w_i)^{2}}\n",
    "$$\n",
    "\n",
    "Попробуем разобраться на простом примере. Рассмотрим функцию от двух переменных:\n",
    "$f(x, y) = \\sin^2 x + \\sin^2 y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb249259-87ef-456f-a904-402b90c82521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w):\n",
    "    \"\"\"\n",
    "    :param w: np.array(np.float) вектор из 2-х элементов\n",
    "    :return: np.float\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.sum(np.sin(w)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115abe74-2f98-4a02-858b-2693dec08355",
   "metadata": {},
   "source": [
    "Обратите внимание, что $x$ - numpy-array вектор длины 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635ed65b-4e40-4924-924b-54253bb8c6d9",
   "metadata": {},
   "source": [
    "***Reminder:***  \n",
    "Что мы хотим? Мы хотим найти минимум этой функции (в машинном обучении мы обычно хотим найти минимум **функции потерь**, например, MSE), а точнее найти $w_1$ и $w_2$ такие, что при них значение $f(w_1, w_2)$ минимально, то есть *точку экстремума*.  \n",
    "  \n",
    "Как мы будем искать эту точку? Используем методы оптимизации (в нашем случае - *минимизации*). Одним из таких методов и является **градиентный спуск**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c32299-e7e3-4600-bf00-064d197f6864",
   "metadata": {},
   "source": [
    "### Задание 1. Градиентный спуск для функции $f$ (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2262d3e-8f6f-4921-af13-e74e4c4e6bbb",
   "metadata": {},
   "source": [
    "Реализуйте функцию, которая будет осуществлять градиентный спуск для функции $f$:\n",
    "\n",
    "*Примечание:* Вам нужно посчитать частные производные именно **аналитически** и **переписать их в код**, а не считать производные численно (через отношение приращения функции к приращению аргумента) -- в этих двух случаях могут различаться ответы, поэтому будьте внимательны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa083d99-7a02-4b6e-8548-9c9ebee381c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_f(w): \n",
    "    \"\"\"\n",
    "    Градиент функциии f, определенной выше.\n",
    "        :param w: np.array[2]: float вектор из 2-х элементов\n",
    "        :return: np.array[2]: float вектор из 2-х элементов\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    YOUR CODE IS HERE\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d184304-6bbd-4626-93c1-56e62fc9f343",
   "metadata": {},
   "source": [
    "Проверим, что градиент принимает вектор из двух чисел и выдает на этой точке верное значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29698da3-07ca-45f6-baff-dd49c82db8c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grad_f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49260/49213570.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m assert np.allclose(grad_f(np.array([1, 2])), \n\u001b[0m\u001b[1;32m      2\u001b[0m                    np.array([0.90929743, -0.7568025])), \"Что-то не так!\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grad_f' is not defined"
     ]
    }
   ],
   "source": [
    "assert np.allclose(grad_f(np.array([1, 2])), \n",
    "                   np.array([0.90929743, -0.7568025])), \"Что-то не так!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0088604b-1d75-4d83-bda8-0d08e909c2cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4110443666.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_49260/4110443666.py\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    curr_w -= #  YOUR CODE. Не забудьте про lr!\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def grad_descent_2d(f, grad_f, lr, num_iter=100, x0=None):\n",
    "    \"\"\"\n",
    "    Функция, которая реализует градиентный спуск в минимум для функции f от двух переменных. \n",
    "        :param f: скалярная функция двух переменных\n",
    "        :param grad_f: функция, возвращающая градиент функции f (устроена как реализованная вами выше grad_f)\n",
    "        :param lr: learning rate алгоритма\n",
    "        :param num_iter: количество итераций градиентного спуска\n",
    "        :return: np.array[num_iter, 2] пар вида (x, f(x))\n",
    "    \"\"\"\n",
    "    \n",
    "    w0 = np.random.random(2)\n",
    "\n",
    "    # будем сохранять значения аргументов и значений функции \n",
    "    # в процессе град. спуска в переменную history\n",
    "    history = []\n",
    "\n",
    "    # итерация цикла == шаг градиентнго спуска\n",
    "    curr_w = w0.copy()\n",
    "    for iter_num in range(num_iter):\n",
    "        entry = np.hstack((curr_w, f(curr_w)))\n",
    "        history.append(entry)\n",
    "    \n",
    "        curr_w -= #  YOUR CODE. Не забудьте про lr!\n",
    "\n",
    "    return np.vstack(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ec67a6-4bac-4d6f-808d-6551cf7a32b4",
   "metadata": {},
   "source": [
    "Визуализируем точки градиентного спуска на 3D-графике нашей функции. Звездочками будут обозначены точки (тройки $w_1, w_2, f(w_1, w_2)$), по которым Ваш алгоритм градиентного спуска двигался к минимуму (Для того, чтобы написовать этот график, мы и сохраняли значения $cur\\_w_1, cur\\_w_2, f(cur\\_w_1, cur\\_w_2)$ в `steps` в процессе спуска).\n",
    "\n",
    "Если у Вас правильно написана функция `grad_descent_2d`, то звездочки на картинке должны сходиться к одной из точек минимума функции. Вы можете менять начальные приближения алгоритма, значения `lr` и `num_iter` и получать разные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67bda638-aa89-4e33-a4cd-bfd52a3178e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_desc_vis(f, grad_f, lr=0.1, num_iter=20):\n",
    "    steps = grad_descent_2d(f, grad_f, lr=lr, num_iter=num_iter)\n",
    "    \n",
    "    X, Y = np.meshgrid(np.linspace(-3, 3, 100), np.linspace(-3, 3, 100))\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    ax = fig.gca(projection=\"3d\")\n",
    "\n",
    "    zs = np.array([f(np.array([x,y]))\n",
    "                  for x, y in zip(np.ravel(X), np.ravel(Y))])\n",
    "    Z = zs.reshape(X.shape)\n",
    "\n",
    "\n",
    "    ax.plot_surface(X, Y, Z, cmap=cm.coolwarm, zorder=2)\n",
    "\n",
    "    ax.plot(xs=steps[:, 0], ys=steps[:, 1], zs=steps[:, 2],\n",
    "            marker=\"*\", markersize=20, zorder=3, \n",
    "            markerfacecolor=\"y\", lw=3, c=\"black\")\n",
    "\n",
    "    ax.set_zlim(0, 5)\n",
    "    ax.view_init(elev=60)\n",
    "    plt.show()\n",
    "    \n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d61bf52-070a-49af-b6a1-20f8777cd99b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grad_f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49260/3851629169.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_desc_vis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'grad_f' is not defined"
     ]
    }
   ],
   "source": [
    "steps = gradient_desc_vis(f, grad_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9926b095-f101-4a0d-b480-e5b1e98e082e",
   "metadata": {},
   "source": [
    "Посмотрим на зависимость значения функции от шага градиентного спуска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "502f4b3e-bce5-42d8-a91b-34c7591bf830",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'steps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49260/3096885406.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Значение функции на каждом шаге гардиентного спуска.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mf_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gradient descent result\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'steps' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "plt.xlabel(\"grad descent step number\")\n",
    "plt.ylabel(\"$f(x)$\")\n",
    "plt.title(\"Значение функции на каждом шаге гардиентного спуска.\")\n",
    "\n",
    "f_values = list(map(lambda x: x[2], steps))\n",
    "plt.plot(f_values, label=\"gradient descent result\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b861f39c-8850-42db-9e9f-23e96652c376",
   "metadata": {},
   "source": [
    "### Задание 2. Реализация линейной регресии (суммарно 9 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357ad605-faf2-4a3a-9d6f-aad2f6a452d4",
   "metadata": {},
   "source": [
    "Так как мы будем использовать градиентный спуск для обучения модели, важной часть является реализация функции потерь и функции для расчета ее градиента. Перем началом стоит напомнить, как считать градиент MSE. Вывод этой формулы можно найти  [здесь](https://medium.com/analytics-vidhya/linear-regression-gradient-descent-intuition-and-math-c9a8f5aeeb22)\n",
    "\n",
    "$$\n",
    "    MSE = \\frac{1}{N}\\sum(y_{true} - y_{pred}) ^ 2\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\nabla{MSE} = \\frac{2}{N} X^T (y_{pred} - y_{true})\n",
    "$$\n",
    "\n",
    "Здесь имеется в виду именно матричное умножение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008e5f3-f2d8-4807-812f-ca2d8b3a5bc5",
   "metadata": {},
   "source": [
    "#### Задание 2.1. MSE и ее градиент (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d96e3cf7-2c6c-4572-a5d8-add05e952bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Функция потерь MSE.\n",
    "        :param y_true: np.array[n_samples]: вектор из правильных ответов\n",
    "        :param y_pred: np.array[n_samples]: вектор из предсказаний модели\n",
    "        :return: значение функции потерь\n",
    "    \"\"\"\n",
    "    \n",
    "    if  y_true.shape[0] != y_pred.shape[0]:\n",
    "        raise ValueError(\"Number of samples in both vectors should be equal\")\n",
    "        \n",
    "    y_true = list(y_true)\n",
    "    value = 0\n",
    "    assert (len(y_pred) == len(y_true))\n",
    "    for m in range(0, len(y_true)):\n",
    "        value += (y_true[m] - y_pred[m]) ** 2\n",
    "    mse_calc = value / len(y_true)\n",
    "    return mse_calc\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "def mse_grad(y_true, y_pred, X):\n",
    "    \"\"\"\n",
    "    Функция для расчета градиента MSE.\n",
    "        :param y_true: np.array[n_samples]: вектор из правильных ответов\n",
    "        :param y_pred: np.array[n_samples]: вектор из предсказаний модели\n",
    "        :param X: np.array[n_samples, n_features]: матрица объекты x признаки\n",
    "        :return: градиент функции потерь MSE\n",
    "    \"\"\"\n",
    "    \n",
    "    if  y_true.shape[0] != y_pred.shape[0]:\n",
    "        raise ValueError(\"Number of samples in both vectors should be equal\")\n",
    "        \n",
    "    \"\"\"\n",
    "    YOUR CODE IS HERE\n",
    "    \"\"\"\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "class MSELoss:\n",
    "    \"\"\"\n",
    "    Класс, реализующий функцию потерь MSE. Нужен для того, чтобы\n",
    "    объединять в одном месте функцию потерь и градиент для нее.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return mse(y_true, y_pred)\n",
    "    \n",
    "    def calculate_gradient(self, y_true, y_pred, X):\n",
    "        return mse_grad(y_true, y_pred, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7728e2-91bb-4925-9ebd-066f51a45a3b",
   "metadata": {},
   "source": [
    "Мы будем использовать следующий класс для расчета градиента наших функций потерь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de02bf42-aa5e-473e-811d-d0f203228c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicGradientDescent:\n",
    "    \"\"\"\n",
    "    Класс, позволяющий делать шаги градиентного спуска,\n",
    "    а также рассчитывающих норму градиента.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, loss_function, grad_norm):\n",
    "        self.loss = loss_function\n",
    "        self.grad_norm = grad_norm\n",
    "        \n",
    "    \n",
    "    def step(self, y, y_pred, X):\n",
    "        grad_i = self.loss.calculate_gradient(y, y_pred, X)\n",
    "        grad_i_norm = self._calculate_grad_norm(grad_i)\n",
    "        \n",
    "        return grad_i, grad_i_norm\n",
    "            \n",
    "            \n",
    "    def _calculate_grad_norm(self, grad_i):\n",
    "        if self.grad_norm == \"l1\":\n",
    "            return np.abs(grad_i).sum()\n",
    "        elif self.grad_norm == \"l2\":\n",
    "            return np.sqrt(np.square(grad_i).sum())\n",
    "        else:\n",
    "            raise ValueError(f\"I can't calculate {self.grad_norm} norm of gradient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9efeb62-1226-4816-ad30-856ca0ac7dcb",
   "metadata": {},
   "source": [
    "В данном задании нужно будет реализовать линейную регрессию и обучить ее при помощи градиентного спуска. Для этого нужно будет заполнять пропуски кода в соответствующих классах. Для начала мы реализуем базовый класс для всех линейных моделей, от которого потом будем наследоваться при реализации линейной и логистической регресий. Не переживайте, этот класс уже реализован, вам достостаточно просто разобраться с кодом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a064fe6a-9ffa-4cb2-8418-b9a0d4c21b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLinearModel:\n",
    "    \"\"\"\n",
    "    Класс, который представляет из себя базовую линейную модель, наследуюясь от которого, мы будем\n",
    "    реализовывать линейную и логистическую регрессии.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate, \n",
    "                 loss_function, fit_intercept,\n",
    "                 n_iter, tol, optimizer, grad_norm):\n",
    "        \"\"\"\n",
    "        Конструктор нашего класса. \n",
    "            :param learning_rate: скорость обучения\n",
    "            :param loss_function: функция потерь (MSE или кросс-энтропия)\n",
    "            :param fit_intercept: нужно ли нам включать свободных член в модель\n",
    "            :param n_iter: количество итераций градиентного спуска\n",
    "            :param tol: параметр для остановки градиентного спуска,\n",
    "                        если норма градиента (l1 или l2) меньше tol, то останавливаемся\n",
    "            :param optimizer: класс, который будет рассчитывать градиент и его норму\n",
    "            :param grad_norm: тип нормы градиента l1 или l2\n",
    "        \"\"\"\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss = loss_function\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.n_iter = n_iter\n",
    "        self.tol = tol\n",
    "        self.grad_norm = grad_norm\n",
    "        self.optimizer = optimizer(loss_function, grad_norm)\n",
    "        \n",
    "        # В начале параметры модели не заданы\n",
    "        self.W = None\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Метод для обучения нашей модели \n",
    "            :param X: матрица объекты x признаки\n",
    "            :param y: вектор значений целевой переменной\n",
    "            :return: обученная модель\n",
    "        \"\"\"\n",
    "        \n",
    "        # Сделаем из y вектор-столбец (n_samples, 1)\n",
    "        y = y.reshape(-1, 1)\n",
    "        n_samples = X.shape[0]\n",
    "        \n",
    "        # Добавим колонку из 1 в матрицу X\n",
    "        if self.fit_intercept:\n",
    "            ones_column = np.ones((n_samples, 1))\n",
    "            X_new = np.hstack((ones_column, X))\n",
    "        \n",
    "        n_features = X_new.shape[1]\n",
    "        \n",
    "        # Инициализируем веса модели\n",
    "        if self.W is None:\n",
    "            self.W = np.random.randn(n_features, 1)\n",
    "        \n",
    "        # Обучаем модель градиентным спуском\n",
    "        for i in range(self.n_iter):\n",
    "            y_pred = self.predict(X)\n",
    "            grad_i, grad_i_norm = self.optimizer.step(y, y_pred, X_new)\n",
    "            \n",
    "            # Если градиент близок к 0, останавливаемся\n",
    "            if grad_i_norm <= self.tol:\n",
    "                return self\n",
    "            \n",
    "            else:\n",
    "                self.W -= self.learning_rate * grad_i\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError(\"It is a basic class for all linear models. You should implement it for descendant class.\")\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Base linear model without prediction skill :(\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f9ba2-ea51-4bd1-a809-cb3d725cb633",
   "metadata": {},
   "source": [
    "#### Задание 2.2. Предсказания линейной регрессии (3 балла)\n",
    "\n",
    "Реализуйте метод `predict` у класса `CustomLinearRegression`, не забудьте про свободный член!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57bf7176-1acf-42ec-9689-d8667ba49ce6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BasicGradientDescent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49260/3959118170.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCustomLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseLinearModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     def __init__(self, learning_rate: float = 1e-2, \n\u001b[1;32m      3\u001b[0m                  \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  n_iter=1000, tol=1e-5, optimizer=BasicGradientDescent, grad_norm=\"l1\"):\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_49260/3959118170.py\u001b[0m in \u001b[0;36mCustomLinearRegression\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     def __init__(self, learning_rate: float = 1e-2, \n\u001b[1;32m      3\u001b[0m                  \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                  n_iter=1000, tol=1e-5, optimizer=BasicGradientDescent, grad_norm=\"l1\"):\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Если вы не проходили наследование и в частности `super`, то не страшно\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BasicGradientDescent' is not defined"
     ]
    }
   ],
   "source": [
    "class CustomLinearRegression(BaseLinearModel):\n",
    "    def __init__(self, learning_rate: float = 1e-2, \n",
    "                 loss_function=MSELoss(), fit_intercept=True,\n",
    "                 n_iter=1000, tol=1e-5, optimizer=BasicGradientDescent, grad_norm=\"l1\"):\n",
    "        \n",
    "        # Если вы не проходили наследование и в частности `super`, то не страшно\n",
    "        # коротко, с помощью этого мы можем вызывать методы родительского класса\n",
    "        # в частности здесь мы используем метод `init`\n",
    "        super().__init__(learning_rate=learning_rate, \n",
    "                         loss_function=loss_function, fit_intercept=fit_intercept,\n",
    "                         n_iter=n_iter, tol=tol, optimizer=optimizer, grad_norm=grad_norm)\n",
    "        \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Метод для вычисления предсказаний \n",
    "            :param X_test: np.array[n_test_samples, n_features]: \n",
    "                           матрица объекты x признаки (тестовый датасет)\n",
    "            :return: y_pred: np.array[n_test_samples, 1]: предсказания модели\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.W is None:\n",
    "            raise NotFittedError(\"This CustomLinearRegression instance is not fitted yet, run fit method.\")\n",
    "        \n",
    "        n_test_samples = X_test.shape[0]\n",
    "        if self.fit_intercept:\n",
    "            ones_column = np.ones((n_test_samples, 1))\n",
    "            X_test = np.hstack((ones_column, X_test))\n",
    "            \n",
    "        \"\"\"\n",
    "        YOUR CODE IS HERE\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"My custom linear regression\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20d6bd1-9d65-4e54-b817-a64358a9dfee",
   "metadata": {},
   "source": [
    "##### Проверим нашу реализацию на простом примере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e35eaf43-d38f-40d6-b901-b7daa2741dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(100, 1)\n",
    "y = 2 * X + 5 + 0.5 * np.random.randn(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3c2603a-85a5-4ae1-8c1d-0174680e80c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e126a10-449d-4d6a-b752-986e9b8bab88",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CustomLinearRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49260/1180150847.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcustom_lin_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'CustomLinearRegression' is not defined"
     ]
    }
   ],
   "source": [
    "custom_lin_reg = CustomLinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae63e50e-4ae6-4fc0-8121-03758417e233",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custom_lin_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49260/3631489517.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcustom_lin_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'custom_lin_reg' is not defined"
     ]
    }
   ],
   "source": [
    "custom_lin_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19d9394a-d9d4-40d0-b772-208d4953cb9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custom_lin_reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49260/1287006609.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_lin_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'custom_lin_reg' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.plot(X, custom_lin_reg.predict(X));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad4bf18-9a5d-4409-b04b-dba080f9ab73",
   "metadata": {},
   "source": [
    "#### Задание 2.3. Используем встроенную линейную регрессию (4 балла)\n",
    "\n",
    "Поработаем с данными о ценах на дома в Бостоне. Постройте модель линейной регресии при помощи `LinearRegression` из `sklearn`. Не забудьте разделить данные на тренировочную и тестовую части, а также правильно предобработать признаки. В конце воспользуйтесь какими-то изученными метриками регресии и сделайте выводы о качестве полученной модели, а также о том, какие признаки наиболее важны с точки зрения полученной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e160cf48-e9ad-4866-aaf0-77429002065f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/miniconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "data = load_boston()\n",
    "X, y = data[\"data\"], data[\"target\"]\n",
    "feature_names = data[\"feature_names\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36099aea-e9c1-4e76-a3c0-bb6f9b8f24ca",
   "metadata": {},
   "source": [
    "Ваш ход:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92ea784d-41a9-45ac-9c75-7307c207020b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6578"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame(X, index = None)\n",
    "\n",
    "dataset.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1c51c06-29ae-4c52-ab38-b018c4b20ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9b67ab6-d5fb-41e2-aa17-3b18d197bb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2    3      4      5     6       7    8      9     10  \\\n",
       "0    0.00632  18.0   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       "1    0.02731   0.0   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       "2    0.02729   0.0   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       "3    0.03237   0.0   2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4    0.06905   0.0   2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       "..       ...   ...    ...  ...    ...    ...   ...     ...  ...    ...   ...   \n",
       "501  0.06263   0.0  11.93  0.0  0.573  6.593  69.1  2.4786  1.0  273.0  21.0   \n",
       "502  0.04527   0.0  11.93  0.0  0.573  6.120  76.7  2.2875  1.0  273.0  21.0   \n",
       "503  0.06076   0.0  11.93  0.0  0.573  6.976  91.0  2.1675  1.0  273.0  21.0   \n",
       "504  0.10959   0.0  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  273.0  21.0   \n",
       "505  0.04741   0.0  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  273.0  21.0   \n",
       "\n",
       "         11    12  \n",
       "0    396.90  4.98  \n",
       "1    396.90  9.14  \n",
       "2    392.83  4.03  \n",
       "3    394.63  2.94  \n",
       "4    396.90  5.33  \n",
       "..      ...   ...  \n",
       "501  391.99  9.67  \n",
       "502  396.90  9.08  \n",
       "503  396.90  5.64  \n",
       "504  393.45  6.48  \n",
       "505  396.90  7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33a18a19-e116-4ab1-a937-08f8f4d345df",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18b9e585-a22c-4b0b-af1c-84ddc01f01b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "lm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3a030-ffac-4417-8819-dd8a401790ce",
   "metadata": {},
   "source": [
    "Predict y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06f088e6-5b17-465f-9e77-2f0fb0c30892",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.6359175 , 24.34133188, 18.05123779, 37.44608042, 14.337726  ,\n",
       "       23.38884817, 18.4703468 , 30.92091819, 20.51937731, 16.30064192,\n",
       "       33.03653808, 23.15136296,  6.3173284 , 24.38641603,  3.77317492,\n",
       "       20.0782365 , 31.77110354, 18.19666599, 12.13475879, 16.72315085,\n",
       "        7.43261344, 26.6577027 , 28.28081331, 25.397913  , 16.21703489,\n",
       "       20.05810612,  6.88600452, 14.30258901, 17.99331959,  2.10546536,\n",
       "       21.52141722, 15.93261099, 13.44135369, 28.61790533, 10.95631699,\n",
       "       27.18993542, 23.72458607, 33.83767147, 22.01953196, 32.02106016,\n",
       "       34.41775792, 23.41731874, 21.57569187, 19.97130021, 26.16555452,\n",
       "       20.59839524, 29.8428036 , 26.48472572, 19.01347417, 34.33288033,\n",
       "        7.98518057, 26.43854313, 12.76820619, 10.90926427, 31.28593158,\n",
       "       23.45770747, 19.77105497, 20.50954373, 16.76087087,  2.60440724,\n",
       "       20.60146485,  7.39710651, 35.91180326, 27.82709497, 30.9929922 ,\n",
       "       24.14312545, 19.96446071, 26.36093014, 18.53660799, 20.44137535,\n",
       "       20.61203131, 20.57236787, 17.61091008, 22.26165039, 35.96490277,\n",
       "       37.82675615, 17.36596543, 14.63749093, 23.89207575, 35.20024069,\n",
       "       24.18395875, 31.84378156, 33.45100869, 23.88677023, 24.5701704 ,\n",
       "       28.08558122,  6.47149416, 21.53599576, 20.64191075, 14.95985711,\n",
       "       30.02018442, 36.53956126, 21.98419708, 24.07125725, 16.7705522 ,\n",
       "       30.61044718, 20.86376446, 35.19014382, 20.75276591, 34.91710601,\n",
       "       13.36008662, 36.41633005, 19.89903469, 22.26498203, 26.57639859,\n",
       "       41.06142079,  5.31876964, 29.10867531, 36.46244325, 22.88851848,\n",
       "       29.71576408, 20.84565327, 33.2628357 , 19.35093211, 41.1331889 ,\n",
       "       16.53211155, 33.92629166, 14.49817297, 27.2366529 , 32.17346412,\n",
       "       29.25294089,  7.57410846, 24.32211646, 27.01133039, 20.05334524,\n",
       "       31.98770138, 15.30512213, 32.50212606, 30.27298338, 24.77278231,\n",
       "       30.74775045, 20.48571224, 13.2934279 , 25.32897353, 32.50865238,\n",
       "       15.39567208, 19.57978632, 27.41845981, 24.6544104 , 34.83102894,\n",
       "       31.52565201, 22.83462747, 21.50983249, 11.83687079, 22.06413428,\n",
       "       19.97311586, 19.64997515, 24.36813782, 16.8769911 , 13.35581347,\n",
       "       27.73351932, 22.66312688, 22.86891905, 26.53945208, 15.01619764,\n",
       "       35.03076093, 27.85797483, 24.02946718, 17.59530431, 12.70425789,\n",
       "       19.12057911, 22.78074236, 15.21956629, 27.903088  , 17.45562207,\n",
       "       25.910306  , 20.37766794, 27.00665171, 10.83570206, 12.93773766,\n",
       "       18.02651543, 27.94103677, 25.54952104, 28.25521667, 17.11121344,\n",
       "       17.35332251, 30.76258538, 25.68755029, 35.82498604, 15.56884279,\n",
       "       34.4899791 , 23.49979052, 24.5164286 , 23.80550868, 26.50029362,\n",
       "       18.59731882, 19.75528681, 32.03366438, 17.97122307, 14.41331042,\n",
       "       18.8821039 , 16.06788471, 23.67524727, 27.99057131, 22.91629921,\n",
       "       14.55488364, 17.18990671, 25.78220367, 18.78364731, 21.1808396 ,\n",
       "       26.94043774, 37.90450439, 20.12833456])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = lm.predict(X_test)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e66c5c-e39f-4cfe-87fb-89dab027bc8e",
   "metadata": {},
   "source": [
    "Some metrics: R2, MSEr2_score(y_test,lin_m.predict(X_tst_st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd44d9bc-f525-43b1-9649-8d2ebb5aed2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7109851558022673"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, lm.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "987f95d3-3832-4a33-b1a4-39e54e6aa16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.38640297232789"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, lm.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3df567-878f-4f94-942e-18c77422281e",
   "metadata": {},
   "source": [
    "### Задание 3. Реализация логистической регресии (суммарно 10 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eb7773-98ab-4451-b83d-6c0c4288137a",
   "metadata": {},
   "source": [
    "Логистическая регрессия не очень сильно отличается от обычной линейной регрессии и используется в задах классификации. Так как здесь мы снова будем пользоваться градиентным спуском, то нужно определить функцию потерь и ее градиент. Одним из самых популярных вариантов в задаче бинарной классификации является бинарная кросс-энтропия (BCE).\n",
    "\n",
    "$$\\mathcal L_{BCE}(y, \\hat y) = -\\sum_i \\left[y_i\\log\\sigma(\\hat y_i) + (1-y_i)\\log(1-\\sigma(\\hat y_i))\\right].$$\n",
    "\n",
    "где $y$ это  таргет желаемого результата и $\\hat y$ является выходом модели. $\\sigma$ - это [*логистическая* функция](https://en.wikipedia.org/wiki/Sigmoid_function), который преобразует действительное число $\\mathbb R$ в вероятность $[0,1]$.\n",
    "\n",
    "Единственная проблема данной функции это возможность получить 0 под знаком логарифма, что не очень хорошо. Попробуем справить с этим \"в лоб\". Скажем, что наши предсказания могут принимать значения от 0 + eps до 1 - eps, где eps очень маленькое число."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6156cf-1749-4a43-b7ea-d469caeb7d01",
   "metadata": {},
   "source": [
    "#### Задание 3.1. Реализация сигмоиды (0.5 баллов)\n",
    "\n",
    "Реализуйте функцию `sigmoid`, которая переводит действительное число $\\mathbb R$ в вероятность $[0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3632a03-f8e3-43e1-9949-2b8019d4c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(output):\n",
    "    # output результат X@w (-inf, +inf)\n",
    "    \"\"\"\n",
    "    YOUR CODE IS HERE\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e243127-1e87-4b70-9205-b2a1c9709054",
   "metadata": {},
   "source": [
    "#### Задание 3.2. BCE Loss и ее градиент (2.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de43d40c-4c9a-4120-b8e6-6dfb41e5d261",
   "metadata": {},
   "source": [
    "Так как мы с вами только начинаем изучать машинное обучение, то было бы слишком жестоко просить вас вычислить градиент BCE Loss (он не так сложен, просто нужно привыкнуть). Поэтому сразу напишем формулу для него:\n",
    "\n",
    "$$\n",
    "\\nabla{\\mathcal L_{BCE}(y, \\hat y), X} = X^T (\\sigma({\\hat{y}}) - y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a5d74-5e8f-4949-a068-8d20c464869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce(y_true, y_pred, eps=1e-15):\n",
    "    \"\"\"\n",
    "    Функция потерь BCE.\n",
    "        :param y_true: np.array[n_samples]: вектор из правильных ответов 0/1\n",
    "        :param y_pred: np.array[n_samples]: вектор из предсказаний модели (вероятности)\n",
    "        :return: значение функции потерь\n",
    "    \"\"\"\n",
    "    \n",
    "    if  y_true.shape[0] != y_pred.shape[0]:\n",
    "        raise ValueError(\"Number of samples in both vectors should be equal\")\n",
    "        \n",
    "    n = y_true.shape[0]\n",
    "    \n",
    "    # So I want escape log(0)\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "    \n",
    "    \"\"\"\n",
    "    YOUR CODE IS HERE\n",
    "    \"\"\"\n",
    "    pass\n",
    "    \n",
    "\n",
    "def bce_grad(y_true, y_pred, X):\n",
    "    \"\"\"\n",
    "    Функция потерь BCE.\n",
    "        :param y_true: np.array[n_samples]: вектор из правильных ответов 0/1\n",
    "        :param y_pred: np.array[n_samples]: вектор из предсказаний модели (вероятности)\n",
    "        :param X: np.array[n_samples, n_features]: матрица объекты x признаки\n",
    "        :return: значение функции потерь\n",
    "    \"\"\"\n",
    "    \n",
    "    if  y_true.shape[0] != y_pred.shape[0]:\n",
    "        raise ValueError(\"Number of samples in both vectors should be equal\")\n",
    "        \n",
    "    \"\"\"\n",
    "    YOUR CODE IS HERE\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class BCELoss:\n",
    "    \"\"\"\n",
    "    Класс, реализующий функцию потерь BCE. Нужен для того, чтобы\n",
    "    объединять в одном месте функцию потерь и градиент для нее.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self, y_true, y_pred):\n",
    "        return bce(y_true, y_pred)\n",
    "    \n",
    "    def calculate_gradient(self, y_true, y_pred, X):\n",
    "        return bce_grad(y_true, y_pred, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7139689e-729b-40e5-b903-c0d9af8880e0",
   "metadata": {},
   "source": [
    "#### Задание 3.3. Предсказания логистической регрессии (2 балла)\n",
    "\n",
    "Реализуйте метод `predict` у класса `CustomLogisticRegression`, не забудьте про свободный член!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b82913-7674-49e6-8f04-8d0d428be019",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLogisticRegression(BaseLinearModel):\n",
    "    def __init__(self, learning_rate: float = 1e-3,\n",
    "                 loss_function=BCELoss(), fit_intercept=True,\n",
    "                 n_iter=1000, tol=1e-5, optimizer=BasicGradientDescent, grad_norm=\"l1\"):\n",
    "        \n",
    "        super().__init__(learning_rate=learning_rate,\n",
    "                         loss_function=loss_function, fit_intercept=fit_intercept,\n",
    "                         n_iter=n_iter, tol=tol, optimizer=optimizer, grad_norm=grad_norm)\n",
    "    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        if self.W is None:\n",
    "            raise NotFittedError(\"This CustomLogisticRegression instance is not fitted, run fit method.\")\n",
    "        \n",
    "        n_test_samples = X_test.shape[0]\n",
    "        if self.fit_intercept:\n",
    "            ones_column = np.ones((n_test_samples, 1))\n",
    "            X_test = np.hstack((ones_column, X_test))\n",
    "            \n",
    "        \"\"\"\n",
    "        YOUR CODE IS HERE\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"My custom logistic regression\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca2d1a-a382-4c1f-bfa3-e23568ff7832",
   "metadata": {},
   "source": [
    "#### Снова проверим работу алгоритма на простом примере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5b577c-032c-4114-b797-9f3d08806e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим датасет из 1 признака и 2 классов\n",
    "X, y = make_classification(n_features=1, n_informative=1,\n",
    "                           n_redundant=0, n_clusters_per_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8ab2c-8a8d-474f-a820-96e61fba35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dfdb15-835a-471a-b4e1-9f93396d21da",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_log_reg = CustomLogisticRegression()\n",
    "custom_log_reg.fit(X, y)\n",
    "y_pred = custom_log_reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b714d857-68b0-401e-88cd-a722712419f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.scatter(X, y_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588c4a67-beac-4566-be93-95eb1e985d26",
   "metadata": {},
   "source": [
    "Проверьте качество работы модели при помощи известных вам метрик бинарной классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c6acd-2257-4f27-aba2-d9ebd585ae32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "916b7736-caf6-4c5d-920d-1d3d9c7b89ea",
   "metadata": {},
   "source": [
    "#### Задание 3.4. Применение логистической регрессии (5 баллов)\n",
    "\n",
    "Мы будем использовать данные по свойствам покемонов (https://www.kaggle.com/abcsds/pokemon). В данном задании вам необходимо сначала сделать краткий EDA (Посмотреть на данные и их распределения, а также посмотреть, как различные признаки связаны между собой и с целевой переменной (`Legendary`))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d29db297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0       65       65     45           1      False  \n",
       "1       80       80     60           1      False  \n",
       "2      100      100     80           1      False  \n",
       "3      122      120     80           1      False  \n",
       "4       60       50     65           1      False  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon = pd.read_csv(\"Pokemon.csv\")\n",
    "pokemon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ed67abc-fb7d-4cbf-8ad7-22d307fa2312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.00000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>362.813750</td>\n",
       "      <td>435.10250</td>\n",
       "      <td>69.258750</td>\n",
       "      <td>79.001250</td>\n",
       "      <td>73.842500</td>\n",
       "      <td>72.820000</td>\n",
       "      <td>71.902500</td>\n",
       "      <td>68.277500</td>\n",
       "      <td>3.32375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>208.343798</td>\n",
       "      <td>119.96304</td>\n",
       "      <td>25.534669</td>\n",
       "      <td>32.457366</td>\n",
       "      <td>31.183501</td>\n",
       "      <td>32.722294</td>\n",
       "      <td>27.828916</td>\n",
       "      <td>29.060474</td>\n",
       "      <td>1.66129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>184.750000</td>\n",
       "      <td>330.00000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>49.750000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>364.500000</td>\n",
       "      <td>450.00000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>539.250000</td>\n",
       "      <td>515.00000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>5.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>721.000000</td>\n",
       "      <td>780.00000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                #      Total          HP      Attack     Defense     Sp. Atk  \\\n",
       "count  800.000000  800.00000  800.000000  800.000000  800.000000  800.000000   \n",
       "mean   362.813750  435.10250   69.258750   79.001250   73.842500   72.820000   \n",
       "std    208.343798  119.96304   25.534669   32.457366   31.183501   32.722294   \n",
       "min      1.000000  180.00000    1.000000    5.000000    5.000000   10.000000   \n",
       "25%    184.750000  330.00000   50.000000   55.000000   50.000000   49.750000   \n",
       "50%    364.500000  450.00000   65.000000   75.000000   70.000000   65.000000   \n",
       "75%    539.250000  515.00000   80.000000  100.000000   90.000000   95.000000   \n",
       "max    721.000000  780.00000  255.000000  190.000000  230.000000  194.000000   \n",
       "\n",
       "          Sp. Def       Speed  Generation  \n",
       "count  800.000000  800.000000   800.00000  \n",
       "mean    71.902500   68.277500     3.32375  \n",
       "std     27.828916   29.060474     1.66129  \n",
       "min     20.000000    5.000000     1.00000  \n",
       "25%     50.000000   45.000000     2.00000  \n",
       "50%     70.000000   65.000000     3.00000  \n",
       "75%     90.000000   90.000000     5.00000  \n",
       "max    230.000000  180.000000     6.00000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acb4c8b8-bde6-488b-9706-0bdb480e210d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Grass', 'Fire', 'Water', 'Bug', 'Normal', 'Poison', 'Electric',\n",
       "       'Ground', 'Fairy', 'Fighting', 'Psychic', 'Rock', 'Ghost', 'Ice',\n",
       "       'Dragon', 'Dark', 'Steel', 'Flying'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon['Type 1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9b3d030-d671-43aa-b1ca-a4e3a2da7062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Grass', 'Fire', 'Water', 'Bug', 'Normal', 'Poison', 'Electric',\n",
       "       'Ground', 'Fairy', 'Fighting', 'Psychic', 'Rock', 'Ghost', 'Ice',\n",
       "       'Dragon', 'Dark', 'Steel', 'Flying'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon['Type 1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4f98076-b160-46ac-ae5e-3fb8f0e61510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Poison', nan, 'Flying', 'Dragon', 'Ground', 'Fairy', 'Grass',\n",
       "       'Fighting', 'Psychic', 'Steel', 'Ice', 'Rock', 'Dark', 'Water',\n",
       "       'Electric', 'Fire', 'Ghost', 'Bug', 'Normal'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon['Type 2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00773226-0645-4af5-a6e2-ef13addf96e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legendary</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">False</th>\n",
       "      <th>#</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057128</td>\n",
       "      <td>0.063622</td>\n",
       "      <td>0.048812</td>\n",
       "      <td>0.065885</td>\n",
       "      <td>0.025615</td>\n",
       "      <td>0.046222</td>\n",
       "      <td>-0.032424</td>\n",
       "      <td>0.984649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>0.057128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586473</td>\n",
       "      <td>0.699817</td>\n",
       "      <td>0.608721</td>\n",
       "      <td>0.685697</td>\n",
       "      <td>0.698582</td>\n",
       "      <td>0.520161</td>\n",
       "      <td>0.015467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HP</th>\n",
       "      <td>0.063622</td>\n",
       "      <td>0.586473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377668</td>\n",
       "      <td>0.192426</td>\n",
       "      <td>0.299471</td>\n",
       "      <td>0.337606</td>\n",
       "      <td>0.109847</td>\n",
       "      <td>0.042132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attack</th>\n",
       "      <td>0.048812</td>\n",
       "      <td>0.699817</td>\n",
       "      <td>0.377668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.437192</td>\n",
       "      <td>0.261879</td>\n",
       "      <td>0.211872</td>\n",
       "      <td>0.305346</td>\n",
       "      <td>0.020456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Defense</th>\n",
       "      <td>0.065885</td>\n",
       "      <td>0.608721</td>\n",
       "      <td>0.192426</td>\n",
       "      <td>0.437192</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.186030</td>\n",
       "      <td>0.475241</td>\n",
       "      <td>-0.040796</td>\n",
       "      <td>0.026482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp. Atk</th>\n",
       "      <td>0.025615</td>\n",
       "      <td>0.685697</td>\n",
       "      <td>0.299471</td>\n",
       "      <td>0.261879</td>\n",
       "      <td>0.186030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.471164</td>\n",
       "      <td>0.393205</td>\n",
       "      <td>0.003415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp. Def</th>\n",
       "      <td>0.046222</td>\n",
       "      <td>0.698582</td>\n",
       "      <td>0.337606</td>\n",
       "      <td>0.211872</td>\n",
       "      <td>0.475241</td>\n",
       "      <td>0.471164</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.212542</td>\n",
       "      <td>0.008990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Speed</th>\n",
       "      <td>-0.032424</td>\n",
       "      <td>0.520161</td>\n",
       "      <td>0.109847</td>\n",
       "      <td>0.305346</td>\n",
       "      <td>-0.040796</td>\n",
       "      <td>0.393205</td>\n",
       "      <td>0.212542</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.041411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generation</th>\n",
       "      <td>0.984649</td>\n",
       "      <td>0.015467</td>\n",
       "      <td>0.042132</td>\n",
       "      <td>0.020456</td>\n",
       "      <td>0.026482</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>-0.041411</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">True</th>\n",
       "      <th>#</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.115444</td>\n",
       "      <td>-0.021318</td>\n",
       "      <td>0.114391</td>\n",
       "      <td>-0.034680</td>\n",
       "      <td>-0.016494</td>\n",
       "      <td>-0.133367</td>\n",
       "      <td>-0.205028</td>\n",
       "      <td>0.992081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>-0.115444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.451218</td>\n",
       "      <td>0.668782</td>\n",
       "      <td>0.105290</td>\n",
       "      <td>0.610607</td>\n",
       "      <td>0.194525</td>\n",
       "      <td>0.142228</td>\n",
       "      <td>-0.123201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HP</th>\n",
       "      <td>-0.021318</td>\n",
       "      <td>0.451218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176166</td>\n",
       "      <td>0.076634</td>\n",
       "      <td>0.029604</td>\n",
       "      <td>0.016942</td>\n",
       "      <td>-0.137105</td>\n",
       "      <td>-0.017262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attack</th>\n",
       "      <td>0.114391</td>\n",
       "      <td>0.668782</td>\n",
       "      <td>0.176166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.210974</td>\n",
       "      <td>0.567287</td>\n",
       "      <td>-0.391433</td>\n",
       "      <td>0.269200</td>\n",
       "      <td>0.093102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Defense</th>\n",
       "      <td>-0.034680</td>\n",
       "      <td>0.105290</td>\n",
       "      <td>0.076634</td>\n",
       "      <td>-0.210974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.510352</td>\n",
       "      <td>0.377674</td>\n",
       "      <td>-0.527786</td>\n",
       "      <td>-0.017889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp. Atk</th>\n",
       "      <td>-0.016494</td>\n",
       "      <td>0.610607</td>\n",
       "      <td>0.029604</td>\n",
       "      <td>0.567287</td>\n",
       "      <td>-0.510352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.154694</td>\n",
       "      <td>0.310406</td>\n",
       "      <td>-0.032872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp. Def</th>\n",
       "      <td>-0.133367</td>\n",
       "      <td>0.194525</td>\n",
       "      <td>0.016942</td>\n",
       "      <td>-0.391433</td>\n",
       "      <td>0.377674</td>\n",
       "      <td>-0.154694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.493259</td>\n",
       "      <td>-0.113199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Speed</th>\n",
       "      <td>-0.205028</td>\n",
       "      <td>0.142228</td>\n",
       "      <td>-0.137105</td>\n",
       "      <td>0.269200</td>\n",
       "      <td>-0.527786</td>\n",
       "      <td>0.310406</td>\n",
       "      <td>-0.493259</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.225116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generation</th>\n",
       "      <td>0.992081</td>\n",
       "      <td>-0.123201</td>\n",
       "      <td>-0.017262</td>\n",
       "      <td>0.093102</td>\n",
       "      <td>-0.017889</td>\n",
       "      <td>-0.032872</td>\n",
       "      <td>-0.113199</td>\n",
       "      <td>-0.225116</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             #     Total        HP    Attack   Defense  \\\n",
       "Legendary                                                                \n",
       "False     #           1.000000  0.057128  0.063622  0.048812  0.065885   \n",
       "          Total       0.057128  1.000000  0.586473  0.699817  0.608721   \n",
       "          HP          0.063622  0.586473  1.000000  0.377668  0.192426   \n",
       "          Attack      0.048812  0.699817  0.377668  1.000000  0.437192   \n",
       "          Defense     0.065885  0.608721  0.192426  0.437192  1.000000   \n",
       "          Sp. Atk     0.025615  0.685697  0.299471  0.261879  0.186030   \n",
       "          Sp. Def     0.046222  0.698582  0.337606  0.211872  0.475241   \n",
       "          Speed      -0.032424  0.520161  0.109847  0.305346 -0.040796   \n",
       "          Generation  0.984649  0.015467  0.042132  0.020456  0.026482   \n",
       "True      #           1.000000 -0.115444 -0.021318  0.114391 -0.034680   \n",
       "          Total      -0.115444  1.000000  0.451218  0.668782  0.105290   \n",
       "          HP         -0.021318  0.451218  1.000000  0.176166  0.076634   \n",
       "          Attack      0.114391  0.668782  0.176166  1.000000 -0.210974   \n",
       "          Defense    -0.034680  0.105290  0.076634 -0.210974  1.000000   \n",
       "          Sp. Atk    -0.016494  0.610607  0.029604  0.567287 -0.510352   \n",
       "          Sp. Def    -0.133367  0.194525  0.016942 -0.391433  0.377674   \n",
       "          Speed      -0.205028  0.142228 -0.137105  0.269200 -0.527786   \n",
       "          Generation  0.992081 -0.123201 -0.017262  0.093102 -0.017889   \n",
       "\n",
       "                       Sp. Atk   Sp. Def     Speed  Generation  \n",
       "Legendary                                                       \n",
       "False     #           0.025615  0.046222 -0.032424    0.984649  \n",
       "          Total       0.685697  0.698582  0.520161    0.015467  \n",
       "          HP          0.299471  0.337606  0.109847    0.042132  \n",
       "          Attack      0.261879  0.211872  0.305346    0.020456  \n",
       "          Defense     0.186030  0.475241 -0.040796    0.026482  \n",
       "          Sp. Atk     1.000000  0.471164  0.393205    0.003415  \n",
       "          Sp. Def     0.471164  1.000000  0.212542    0.008990  \n",
       "          Speed       0.393205  0.212542  1.000000   -0.041411  \n",
       "          Generation  0.003415  0.008990 -0.041411    1.000000  \n",
       "True      #          -0.016494 -0.133367 -0.205028    0.992081  \n",
       "          Total       0.610607  0.194525  0.142228   -0.123201  \n",
       "          HP          0.029604  0.016942 -0.137105   -0.017262  \n",
       "          Attack      0.567287 -0.391433  0.269200    0.093102  \n",
       "          Defense    -0.510352  0.377674 -0.527786   -0.017889  \n",
       "          Sp. Atk     1.000000 -0.154694  0.310406   -0.032872  \n",
       "          Sp. Def    -0.154694  1.000000 -0.493259   -0.113199  \n",
       "          Speed       0.310406 -0.493259  1.000000   -0.225116  \n",
       "          Generation -0.032872 -0.113199 -0.225116    1.000000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon.groupby('Legendary').corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d89ccc",
   "metadata": {},
   "source": [
    "Мы будем предсказывать является ли покемон легендарным или нет. Замените логическое значение колонки на числовое (перекодировав на 0 и 1). Также подумайте, как в этом случае лучше закодировать категориальные признаки (может быть, лучше их просто выбросить?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0db7a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon.Legendary = pd.get_dummies(pokemon.Legendary)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e09fa0",
   "metadata": {},
   "source": [
    "Разделите ваши данные на тестовую и тренировочную выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e68671bd-8082-4ac7-a159-13e8e8563049",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(pokemon)\n",
    "y = np.array(np.matrix(pokemon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eaa6f41d-4c30-4c37-9a7d-ada749df57e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 'Bulbasaur', 'Grass', ..., 45, 1, 0],\n",
       "       [2, 'Ivysaur', 'Grass', ..., 60, 1, 0],\n",
       "       [3, 'Venusaur', 'Grass', ..., 80, 1, 0],\n",
       "       ...,\n",
       "       [720, 'HoopaHoopa Confined', 'Psychic', ..., 70, 6, 1],\n",
       "       [720, 'HoopaHoopa Unbound', 'Psychic', ..., 80, 6, 1],\n",
       "       [721, 'Volcanion', 'Fire', ..., 70, 6, 1]], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7f13d833-1b3f-44bb-bf9d-7caefebe5c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 'Bulbasaur', 'Grass', ..., 45, 1, 0],\n",
       "       [2, 'Ivysaur', 'Grass', ..., 60, 1, 0],\n",
       "       [3, 'Venusaur', 'Grass', ..., 80, 1, 0],\n",
       "       ...,\n",
       "       [720, 'HoopaHoopa Confined', 'Psychic', ..., 70, 6, 1],\n",
       "       [720, 'HoopaHoopa Unbound', 'Psychic', ..., 80, 6, 1],\n",
       "       [721, 'Volcanion', 'Fire', ..., 70, 6, 1]], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8baef1f8-7617-406b-9b3e-c3bd51f43c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp_train, Xp_test, yp_train, yp_test = train_test_split(X, y, test_size = 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321d3f38",
   "metadata": {},
   "source": [
    "Обучите модель `LogisticRegression` из `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c432c38a-7ebf-4b3c-bb87-60d49a0d5787",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Palpitoad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49260/3651644187.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mXp_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXp_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXp_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_trasnform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXp_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[1;32m    840\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Palpitoad'"
     ]
    }
   ],
   "source": [
    "Xp_train, Xp_test = scaler.fit_transform(Xp_train), scaler.fit_trasnform(Xp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "055a3228-36df-4bf3-9f0b-3bdf15505375",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Palpitoad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_49260/873446307.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXp_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myp_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1506\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1509\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Palpitoad'"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(Xp_train, yp_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dc12fe",
   "metadata": {},
   "source": [
    "Выведите метрики вашего классификатора:\n",
    "\n",
    "1. Нарисуйте [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html).\n",
    "\n",
    "2. Изобразите ROC кривую и посчитайте площадь под ней.\n",
    "\n",
    "3. Скажите, какие признаки оказались наиболее важны для модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f58f5a-3b46-4562-b4bb-6d09c9a5fb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96c048e4-6624-4a94-af92-650d109ac581",
   "metadata": {},
   "source": [
    "### Задание 4. Расскажите о вашей любимой музыкальной группе (исполнителе) (0.5 балла)\n",
    "\n",
    "Расскажите, как вы познакомились с этой группой и скиньте несколько наиболее любимых треков)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77460d19-2e4e-4895-a29c-64687aab94e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8441428d-5ff4-46e0-927f-47ee935b224d",
   "metadata": {},
   "source": [
    "## Therapy time\n",
    "\n",
    "Напишите здесь ваши впечатления о задании: было ли интересно, было ли слишком легко или наоборот сложно и тд. Также сюда можно написать свои идеи по улучшению заданий, а также предложить данные, на основе которых вы бы хотели построить следующие дз. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a2c8ee-96ac-4967-a9d5-55563826ee1d",
   "metadata": {},
   "source": [
    "**Ваши мысли:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546c0947-5835-46d4-987f-95248bf7613d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
